---
layout: post
title: 音视频开发进阶指南笔记（1）
tags:
  - 音视频
---


# 音视频开发进阶指南笔记（1）

## 一、基础概念

### 1.1 声音的物理性质

#### 1.1.1 声音是波

#### 1.1.2 声波的三要素

* 频率： 频率高，波长短，长波更容易绕过障碍物，可以传递的更远
* 响度： 就是声音大小
* 音色： 波形代表了声音的音色

人耳的听力范围 是20 - 20k Hz

![等响曲线](https://zhouxiaofei-image.oss-cn-hangzhou.aliyuncs.com/images/20190613111028.png)

人耳堆3 - 4 Hz 的范围内的声音比较敏感

#### 1.1.3 声音的传播介质

吸音棉，隔音棉

#### 1.1.4 回声

就是声音的反弹

#### 1.1.5 共鸣

声音的传播也是一种能量的传播过程  

### 1.2 数字音频

数字音频有三个概念

* 采样： 就是在时间轴上堆信号进行数字化，根据耐奎斯特定理（采样定理），按照比声音最高频率两倍以上的频率对声音进行采样（也成为AD转换）
* 量化：在幅度轴胜对信号进行数字化，比如用16比特的二进制信号表示声音的一个采样
* 编码： 按照一定的格式记录采样和量化后的数字数据，比如顺序存储或压缩存储等    

通常所说的裸数据格式就是脉冲编码调制（PCM）数据。 描述一段PCM数据一般需要以下几个概念： *量化格式，采样率，声道数。 以CD音质为例： 量化格式为16比特，采样率为44100，声道数为2   

对于声音格式，还有一个概念来描述它的大小，成为数据比特率，即一秒时间内的比特数目。用于衡量音频数据单位时间内的容量大小， 对于CD音质来说，比特率就是 44100 * 16 * 2 kps     

在一分钟的时间内，这类CD音质的数据需要占据的空间： 44100 * 16 * 2 / 1000 * 60 / 8 / 1024 M  

如果sampleFormat更精确，或者 sampleRate更密集， 那么所占的空间就会更大，同时描述的声音细节就会更精确。   

#### 麦克风是如何采集数据的

麦克风里面有一层碳膜，非常薄且十分灵敏，声波会压缩空气，进而压缩这层碳膜，碳膜在受到挤压的时候也会发出震动，在碳膜的下方就是一个电极，碳膜在震动的时候会接触电极，接触时间长短和频率与声波的震动幅度和频率有关，这样就玩成了声音信号到电信号的转换。之后再经过放大电路的处理，就可以实施采样量化处理了。   


### 1.3 音频编码   

网络传播中需要对声音进行压缩编码，压缩编码的基本指标之一就是压缩比，通常小于1（废话）。   

压缩算法有__有损压缩__ 和 __无损压缩__， 无损压缩是指解压后的数据可以完全复原。  有损压缩反之，常用的格式中，无损压缩用的较多。   根据不同需求，采用不同的压缩编码算法。  如，PCM、WAV、AAC、MP3、Ogg等    

压缩编码的原理实际上是压缩掉冗余信号（不能被人耳感知的信号），包含听觉范围之外的音频信号以及被掩盖掉的音频信号   

#### 常用的编码格式

* WAV： 一种实现，就是在PCM数据格式前面加上44 字节，分别用来描述 PCM的采样率，声道数，数据格式等信息   特点： 音质好，适配范围广
* MP3编码： MP3具有不错的压缩比， 特点： 音质在 128 Kbit/s以上表现不错，压缩比较高
* AAC编码： 通过一些附加的编码技术（PS，SBR 等），衍生出来 LC—AAC，HE—AAC，HE-AAC v2 三种主要的编码格式。分别对应 高码率（>80Kbit/s），中码率，和低码率（<48Kbit/s），特点： 低码率下表现优异，并且多用于视频中的音频解码。
* Ogg编码： 在各个码率下都有优异的表现，尤其是中低码率下。。 但是目前还没有媒体服务软件的支持 ， 特点： 表现优异，但是兼容性不够好，流媒体特性不支持。。使用与语音聊天的音频消息场景 

### 1.4 图像的物理现象  

视频是由一幅幅图像组成的，所以要学习视频还得从学习图像开始   

看到物体是因为光的反射   

### 1.5 图像的数值表示  

#### 1.5.1 RGB 的表示方式   

像素里面的子像素如何表示 ？ 

* 浮点表示： 取值范围为0.0 - 1.0 ，openGL ES 就是如此
* 整数表示： 取值范围是0-255， 8个比特表示一个子像素，32 个比特表示一个像素（4个颜色通道），有些平台表示一个像素的比特也不相同。。图像也使用压缩格式在网络上传播（jpg，png等），但是对于视频来说，这种压缩不能直接用于视频压缩，因为视频除了考虑帧内编码，也要考虑帧间编码，视频压缩采用的是更成熟的算法。

#### 1.5.2 YUV 表示方式  

对于视频帧的裸数据表示，更多采用的是YUV 数据格式，只要用于优化彩色视频信号的传输相比，最大的有点在于只需要占用极少的带宽， Y （表示明亮度），U和V 代表色度，他们的作用是描述影像的色彩以及饱和度，永来指定像素的颜色。。  

亮度 是透过RGB 输入信号来建立的，方法是将RGB 的特定部分叠加道一起。。   
色度 定义了颜色的两个方面，颜色和饱和度，分别用 Cr 和 Cb表示，其中Cr 表示了RGB 输入信号红色部分与RGB信号亮度值之间的差异，而Cb 表示的是 RGB蓝色部分与RGB信号亮度值之间的差异   

永YUV 的原因是 它的亮度信号Y 和色度信号 U，V 是分离的，    
最常用的表示形式是 Y、U、V都使用8个字节为准，所以取值范围就是0-255， 在广播电视系统中不传输很低和很高的数值，实际上是为了防止信号变动造成过载，所以把两边的数值作为“保护带”， Y 的取值大概在16 - 235， UV 的取值在16 - 240，   

### 1.6 视频的编码方式

#### 1.6.1 视频编码

同样是去除冗余信息：  

* 运动补偿： 通过先前的局部图像来预测、补偿当前的局部图像，从而减少帧序列冗余信息   
* 运动表示： 不同区域的图像需要使用不同的运动矢量来描述运动信息
* 运动估计： 运动估计是从视频序列中抽取运动信息的一整套技术   

使用帧内编码可以去除空间上的冗余信息，Motion JPEG即 MPEG，是适用于动态视频的压缩算法。。除了对单幅图像进行编码外，还利用图像序列中的相关原则除去冗余，这样可以大大提高视频的压缩比， 目前主要有以下几个版本：  Mpeg1（VCD），Mpeg2（DVD）， Mpeg4 AVC（目前流媒体主要使用）   

相比较于 ISO 制定的MPEG 标准，ITU-T 制定的H.261 ,H.262, H.263, H.264 一系列视频编码标准是一套单独的体系，其中，H.264 集中了以往标准的所有优点，并吸取了以往的标准经验。这使得他比 MPeg更好推广，目前使用最多的就是这个。   

H.264 创造了多参考帧，多块类型，整数转换，帧内预测等新的压缩技术，使用了更精细的分像素运动矢量，和新一代的环路滤波器，大大提高了压缩性能。


#### 1.6.2 编码概念

##### 1. IPB 帧

压缩每一帧的数据   
GOP说白了就是两个I帧之间的间隔.比较说GOP为120,如果是720p60的话,那就是2s一次I帧. 

* I frame ：帧内编码帧 又称intra picture，I 帧通常是每个 GOP（MPEG 所使用的一种视频压缩技术）的第一个帧，经过适度地压缩，做为随机访问的参考点，可以当成图象。I帧可以看成是一个图像经过压缩后的产物。

* P frame: 前向预测编码帧 又称predictive-frame，通过充分将低于图像序列中前面已编码帧的时间冗余信息来压缩传输数据量的编码图像，也叫预测帧；

* B frame: 双向预测内插编码帧 又称bi-directional interpolated prediction frame，既考虑与源图像序列前面已编码帧，也顾及源图像序列后面已编码帧之间的时间冗余信息来压缩传输数据量的编码图像，也叫双向预测帧；

* PTS：Presentation Time Stamp。PTS主要用于度量解码后的视频帧什么时候被显示出来

* DTS：Decode Time Stamp。DTS主要是标识读入内存中的ｂｉｔ流在什么时候开始送入解码器中进行解码。

在没有B帧存在的情况下DTS的顺序和PTS的顺序应该是一样的。

### 2.1 创建xcode项目，添加C++支持

### 2.3 交叉编译的原理与实践

#### 2.3.1 交叉编译的原理

交叉编译： 在一个平台上，生成另外一个平台的可执行代码，相较于正常编译，：

* 首先，最终运行程序的设备就是iOS 或安卓设备，源代码就是下载的或者自己编写的源代码，编译机器就是自己的pC，编译器也在PC上面，编译器就是交叉工具编译链   

无论是自行安装的编译器，还是下载其他平台的交叉工具编译链，他们都会提供以下几个工具：  CC， AS， AR， LD， NM， GDB，

* CC： 编译器，对C 源文件进行编译处理
* AS： 将汇编文件生成目标文件（翻译称机器码）
* AR： 打包器，用于库操作，可以通过该工具从一个库中删除或者增加代码模块
* LD： 链接器，为前面生成的目标代码分配地址空间，将多个文件链接称一个库或者是可执行文件
* GDB： 调试工具，可以对运行过程中的代码进行调试
* STRIP： 以最终生成的可执行文件或者库文件作为输入，然后消除掉其中的源码
* NM： 查看静态库文件中的符号表
* OBJdump： 查看静态库或者动态库的方法签名  


##### LAME 的交叉编译

LAME 是一款非常优秀的MP3 编码引擎，在业界是最常用的。如果在移动端编码MP3文件，使用LAME 就成为了唯一的选择。   

iOS 交叉编译工具链是随着Xcode 一起安装的，所以不需要自己单独下载安装。  

下载LAME 的最新版本 [链接地址](https://sourceforge.net/projects/lame/files/lame/3.99/)


书里面的编译代码有问题， 查看[这个链接](https://www.jianshu.com/p/a98ef8a396ea)

##### FDK_AAC 的交叉编译

FDK_AAC 简介： 
	是用来编码和解码AAC 格式音频文件的开源库，安卓系统使用的就是这个，FDK_AAC 几乎支持大部分的Profile， 并且支持CBR和VBR 这两种模式，    
下载[稳定版本](https://sourceforge.net/p/opencore-amr/fdk-aac/ci/v0.1.4/tree/)

同上，编译代码查看[这里](https://blog.csdn.net/zhjw1991/article/details/80406104)

## 3. FFmpeg

开源框架，可以用来记录、处理、数字音视频，并转换为流的开源框架，采用LPL或GPL 许可证，提供了录制，转换以及流化音视频的完整解决方案，跨平台特性非常强大，FF 是fast forward的缩写    

### 3.1 编译

#### 1. 编译选项详解

* 下载FFmpeg
* FFmpeg 与大部分GNU 软件的编译方式类似，都是通过configure脚本来实现编译前定制的。
* configure脚本运行完毕之后，会生成config.mk 和config.h 两个文件，分别作用道makefile和源代码的层次，由这两个部分协同实现对编译选项的控制。
	* 标准选项： CNU 软件例行配置，例如安装路径， --prefix等
	* 编译、链接选项： 默认配置是生成静态库，例如 -disable-static， --enable-shared等
	* 可执行程序控制选项，决定是否生成FFmpeg，ffplay，ffprobe和ffserver等
	* 模块控制选项： 裁剪编译模块，包括整个库的裁剪，例如--disable-avdevice， 一组模块的筛选，例如--disable-decoders； 单个模块的裁剪， 例如disable-demuxer
	* 能力展示选项： 列出当前源码支持的各种能力集，例如--list-decoders
	* 其他： 允许开发者深度定制，例如交叉编译环境配置，自定以编译器参数的设定等等

下图是整体结构

![FFmpeg结构图](https://zhouxiaofei-image.oss-cn-hangzhou.aliyuncs.com/images/20190613175223.png)



默认的编译会生称4个可执行文件和8个静态库，可执行文件包括： 

* 用于转码、推流、Dump媒体文件的ffmpeg
* 用于播放媒体文件的ffplay
* 用于获取媒体文件信息的ffprobe
* 以及作为简单流媒体服务器的ffserver

8个静态库其实就是FFmpeg 的8个模块

* AVUtil： 核心工具库，基础模块库，其他模块几乎都会依赖
* AVFormat 文件格式和协议库，最重要的模块之一，封装了protocol曾和Demuxer， Muxer层，使协议和格式对于开发者来说是透明的

	> muxer是指合并文件，即将视频文件、音频文件和字幕文件合并为某一个视频格式。比如把rmvb格式的视频，mp3格式的音频文件以及srt格式的字幕文件，合并成为一个新的mp4或者mkv格式的文件。
	
* AVCodec: 编码解码库，也是重要模块之一，封装了Codec层，但是有一些Codec是具备自己的License的，FFmpeg是不会默认添加 libx264， FDK-AAC 等库的，但是FFmpeg就像一个平台，可以将其他的第三方Codec 以插件的形式添加进来，然后为开发者提供统一的接口。
* AVFilter： 音视频滤镜库，提供了包括音频特效和视频特效的处理，在使用FFmpeg 的API进行边解码的过程中，直接使用这个模块为音视频数据做特效处理，非常方便和高校
* AVDevice： 输入输出设别库， 比如，需要编译出播放声音或者播放视频的工具ffplay， 就需要确保该模块是打开的，，同事也需要libSDL的预先编译，因为该设备模块播放声音与播放视频使用的都是libSDL库  
* SwrRessample： 可以用于音频重采样，可以对数字音频进行声道数、数据格式、采样率等多种基本信息的转换。 
* SWScale： 将图像进行格式转化的模块，比如，可以将YUV 的数据转换为RGB 的数据
* PostProc： 可以用于后期树立，当我门使用AVFilter 的时候，需要打开这个模块的开关，因为Filter模块会用到这个模块的基础函数  

如何引入第三方编码库？  

* 在FFmpeg 源码目录下建立 external-libs 目录
	
